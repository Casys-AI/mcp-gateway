{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DAG Workflow Execution\n",
        "\n",
        "Execute multi-step workflows with dependencies using the DAG (Directed Acyclic Graph) executor.\n",
        "\n",
        "**Features:**\n",
        "- Parallel execution of independent tasks\n",
        "- Dependency management between tasks\n",
        "- State management and checkpoints\n",
        "- Event streaming for real-time progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Setup"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import {\n",
        "  DenoSandboxExecutor,\n",
        "  ParallelExecutor,\n",
        "  createInitialState,\n",
        "  type DAGExecutionResult,\n",
        "  type ToolExecutor\n",
        "} from \"jsr:@casys/mcp-gateway\";\n",
        "\n",
        "// Create sandbox for code execution\n",
        "const sandbox = new DenoSandboxExecutor({\n",
        "  timeout: 5000,\n",
        "  memoryLimit: 128,\n",
        "});\n",
        "\n",
        "console.log(\"‚úÖ DAG executor ready\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Define a Simple DAG\n\nCreate a workflow with 3 tasks:\n```\nfetchData ‚Üí processData ‚Üí aggregate\n```"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "const dag = {\n",
        "  tasks: {\n",
        "    fetchData: {\n",
        "      tool: \"sandbox\",\n",
        "      params: { code: \"return { numbers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] }\" },\n",
        "      dependencies: []\n",
        "    },\n",
        "    processData: {\n",
        "      tool: \"sandbox\",\n",
        "      params: { code: \"return context.numbers.map(n => n * n)\" },\n",
        "      dependencies: [\"fetchData\"]\n",
        "    },\n",
        "    aggregate: {\n",
        "      tool: \"sandbox\",\n",
        "      params: { code: \"return { sum: context.reduce((a, b) => a + b, 0), count: context.length }\" },\n",
        "      dependencies: [\"processData\"]\n",
        "    }\n",
        "  }\n",
        "};\n",
        "\n",
        "console.log(\"üìä DAG defined:\");\n",
        "console.log(\"   Tasks:\", Object.keys(dag.tasks).join(\" ‚Üí \"));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Execute DAG Manually\n\nStep through each task to see how it works:"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Execute fetchData\n",
        "console.log(\"\\nüì• Step 1: fetchData\");\n",
        "const result1 = await sandbox.execute(dag.tasks.fetchData.params.code);\n",
        "console.log(\"   Result:\", result1.result);\n",
        "\n",
        "// Execute processData with context from fetchData\n",
        "console.log(\"\\n‚öôÔ∏è  Step 2: processData\");\n",
        "const result2 = await sandbox.execute(\n",
        "  dag.tasks.processData.params.code,\n",
        "  result1.result // Pass previous result as context\n",
        ");\n",
        "console.log(\"   Result:\", result2.result);\n",
        "\n",
        "// Execute aggregate with context from processData\n",
        "console.log(\"\\nüìä Step 3: aggregate\");\n",
        "const result3 = await sandbox.execute(\n",
        "  dag.tasks.aggregate.params.code,\n",
        "  result2.result\n",
        ");\n",
        "console.log(\"   Result:\", result3.result);\n",
        "\n",
        "console.log(\"\\n‚úÖ Workflow complete!\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Parallel DAG Execution\n\nNow with tasks that can run in parallel:\n```\n    ‚îå‚îÄ taskA ‚îÄ‚îê\nstart‚îÇ         ‚îÇ‚Üí combine\n    ‚îî‚îÄ taskB ‚îÄ‚îò\n```"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "const parallelDag = {\n",
        "  tasks: {\n",
        "    taskA: {\n",
        "      tool: \"sandbox\",\n",
        "      params: { code: \"return { source: 'A', value: Math.random() * 100 }\" },\n",
        "      dependencies: []\n",
        "    },\n",
        "    taskB: {\n",
        "      tool: \"sandbox\",\n",
        "      params: { code: \"return { source: 'B', value: Math.random() * 100 }\" },\n",
        "      dependencies: []\n",
        "    },\n",
        "    combine: {\n",
        "      tool: \"sandbox\",\n",
        "      params: { code: \"return { total: context.A.value + context.B.value, sources: [context.A.source, context.B.source] }\" },\n",
        "      dependencies: [\"taskA\", \"taskB\"]\n",
        "    }\n",
        "  }\n",
        "};\n",
        "\n",
        "console.log(\"üîÄ Parallel DAG:\");\n",
        "console.log(\"   taskA (no deps)\");\n",
        "console.log(\"   taskB (no deps)\");\n",
        "console.log(\"   combine (depends on A and B)\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Execute A and B in parallel\n",
        "console.log(\"\\n‚ö° Executing taskA and taskB in parallel...\");\n",
        "\n",
        "const [resultA, resultB] = await Promise.all([\n",
        "  sandbox.execute(parallelDag.tasks.taskA.params.code),\n",
        "  sandbox.execute(parallelDag.tasks.taskB.params.code)\n",
        "]);\n",
        "\n",
        "console.log(\"   taskA:\", resultA.result);\n",
        "console.log(\"   taskB:\", resultB.result);\n",
        "\n",
        "// Combine results\n",
        "console.log(\"\\nüîó Combining results...\");\n",
        "const combined = await sandbox.execute(\n",
        "  parallelDag.tasks.combine.params.code,\n",
        "  { A: resultA.result, B: resultB.result }\n",
        ");\n",
        "\n",
        "console.log(\"   Combined:\", combined.result);\n",
        "console.log(\"\\n‚úÖ Parallel workflow complete!\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Complex DAG with Multiple Layers\n\n```\n       ‚îå‚îÄ extract ‚îÄ‚îê\nfetch ‚îÄ‚îº‚îÄ validate ‚îÄ‚îº‚îÄ transform ‚îÄ save\n       ‚îî‚îÄ enrich ‚îÄ‚îÄ‚îò\n```"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "const complexDag = {\n",
        "  tasks: {\n",
        "    fetch: {\n",
        "      code: \"return { users: [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}] }\",\n",
        "      deps: []\n",
        "    },\n",
        "    extract: {\n",
        "      code: \"return context.users.map(u => u.name)\",\n",
        "      deps: [\"fetch\"]\n",
        "    },\n",
        "    validate: {\n",
        "      code: \"return { valid: context.users.every(u => u.id && u.name), count: context.users.length }\",\n",
        "      deps: [\"fetch\"]\n",
        "    },\n",
        "    enrich: {\n",
        "      code: \"return context.users.map(u => ({ ...u, createdAt: new Date().toISOString() }))\",\n",
        "      deps: [\"fetch\"]\n",
        "    },\n",
        "    transform: {\n",
        "      code: \"return { names: context.extract, isValid: context.validate.valid, enriched: context.enrich }\",\n",
        "      deps: [\"extract\", \"validate\", \"enrich\"]\n",
        "    },\n",
        "    save: {\n",
        "      code: \"return { saved: true, summary: `Saved ${context.names.length} users, valid: ${context.isValid}` }\",\n",
        "      deps: [\"transform\"]\n",
        "    }\n",
        "  }\n",
        "};\n",
        "\n",
        "// Execute layer by layer\n",
        "const results: Record<string, unknown> = {};\n",
        "\n",
        "console.log(\"üèóÔ∏è  Executing complex DAG...\\n\");\n",
        "\n",
        "// Layer 1: fetch\n",
        "console.log(\"Layer 1: fetch\");\n",
        "results.fetch = (await sandbox.execute(complexDag.tasks.fetch.code)).result;\n",
        "console.log(\"   ‚úì fetch complete\");\n",
        "\n",
        "// Layer 2: extract, validate, enrich (parallel)\n",
        "console.log(\"\\nLayer 2: extract, validate, enrich (parallel)\");\n",
        "const [extract, validate, enrich] = await Promise.all([\n",
        "  sandbox.execute(complexDag.tasks.extract.code, results.fetch),\n",
        "  sandbox.execute(complexDag.tasks.validate.code, results.fetch),\n",
        "  sandbox.execute(complexDag.tasks.enrich.code, results.fetch)\n",
        "]);\n",
        "results.extract = extract.result;\n",
        "results.validate = validate.result;\n",
        "results.enrich = enrich.result;\n",
        "console.log(\"   ‚úì extract, validate, enrich complete\");\n",
        "\n",
        "// Layer 3: transform\n",
        "console.log(\"\\nLayer 3: transform\");\n",
        "results.transform = (await sandbox.execute(\n",
        "  complexDag.tasks.transform.code,\n",
        "  { extract: results.extract, validate: results.validate, enrich: results.enrich }\n",
        ")).result;\n",
        "console.log(\"   ‚úì transform complete\");\n",
        "\n",
        "// Layer 4: save\n",
        "console.log(\"\\nLayer 4: save\");\n",
        "results.save = (await sandbox.execute(\n",
        "  complexDag.tasks.save.code,\n",
        "  results.transform\n",
        ")).result;\n",
        "console.log(\"   ‚úì save complete\");\n",
        "\n",
        "console.log(\"\\nüìä Final result:\");\n",
        "console.log(JSON.stringify(results.save, null, 2));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**DAG Workflows enable:**\n",
        "- ‚úÖ Sequential task execution with dependencies\n",
        "- ‚úÖ Parallel execution of independent tasks\n",
        "- ‚úÖ Context passing between tasks\n",
        "- ‚úÖ Complex multi-layer workflows\n",
        "\n",
        "**Use cases:**\n",
        "- ETL pipelines\n",
        "- Data processing workflows\n",
        "- Multi-step AI agent tasks\n",
        "- Orchestrated tool execution"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Deno", "language": "typescript", "name": "deno"},
    "language_info": {"file_extension": ".ts", "mimetype": "text/x.typescript", "name": "typescript"}
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
